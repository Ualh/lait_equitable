---
editor: 
  markdown: 
    wrap: sentence
---

# Data

-   Sources
-   Description
-   Wrangling/cleaning
-   Spotting mistakes and missing data (could be part of EDA too)
-   Listing anomalies and outliers (could be part of EDA too)

### Market for dairy products in Switzerland

The dairy market is an important sector of Swiss agriculture and the agri-food industry. The dairy industry accounts for around 20% of agricultural production. 

Our data source is the Swiss Federal Office for Agriculture, OFAG. The dataset shows price trends on the dairy market at production level. The farmgate milk price is calculated on the basis of a monthly survey of the main milk buyers. These are the companies that buy milk directly from producers. International milk price trends are also shown for comparison purposes, we will look at this later.

Source - https://www.donnees-agrimarche.ch/donnees

```{r}
# Installer les packages nécessaires si ce n'est pas déjà fait
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("lubridate", quietly = TRUE)) install.packages("lubridate")
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
if (!requireNamespace("forcats", quietly = TRUE)) install.packages("forcats")
if (!requireNamespace("readxl", quietly = TRUE)) install.packages("readxl")
if (!requireNamespace("data.table", quietly = TRUE)) install.packages("data.table")
if (!requireNamespace("kableExtra", quietly = TRUE)) install.packages("kableExtra")
if (!requireNamespace("plotly", quietly = TRUE)) install.packages("plotly")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("reactable", quietly = TRUE)) install.packages("reactable")
if (!requireNamespace("readr", quietly = TRUE)) install.packages("readr")

library(dplyr)
library(lubridate)
library(tidyr)
library(forcats)
library(readxl)
library(data.table)
library(kableExtra)
library(plotly)
library(ggplot2)
library(reactable)
library(readr)
```

#### Wrangling and Cleaning

We start by removing the columns with no value or unique value, and the variables that are not relevant for our analysis. After proceeding, we end up with a sub-data set of 6 variables.

```{r}
# Importer les données
data <- read.csv('../data/Données_marché_Lait.csv')

# Faire une copie des données
clean_data <- data

# Supprimer les colonnes avec des valeurs uniques
columns_to_drop <- c('Devise', 'Composants.de.coûts', 'Devise', 'Type.de.données', 'Source.de.données', 
                     'Groupe.de.produits', 'Commerce.extérieur', 'Indicateur', 'Marché', 
                     'Propriétés.du.produit', "Mode.d.utilisation", 'Unité', 'Produit', 
                     'Echelon.de.création.de.valeur', 'Echelon.de.création.de.valeur_Détail')

clean_data <- clean_data %>%
  select(-all_of(columns_to_drop))

clean_data$Date <- as.Date(paste0("01-", clean_data$Date), format="%d-%m-%Y")

# Renommer les colonnes
clean_data <- clean_data %>%
  rename(
    `System of production` = `Système.de.production`,
    `Product origin` = `Provenance.du.produit`,
    `Product subgroup` = `Sous.groupe.de.produits`,
    `Sales region` = `Région.de.vente`,
    `Price` = `Prix`
  )

# Changer les valeurs catégorielles dans les colonnes spécifiées
clean_data <- clean_data %>%
  mutate(`System of production` = recode(`System of production`, 'Conventionnel' = 'Conventional'),
         `Product origin` = recode(`Product origin`,
                                   'Région 1' = 'Region 1',
                                   'Région 2' = 'Region 2',
                                   'Région 3' = 'Region 3',
                                   'Région 4' = 'Region 4',
                                   'Région 5' = 'Region 5',
                                   'Suisse' = 'Switzerland',
                                   'Reste du monde, non suisse' = 'Rest of the world, non-Swiss',
                                   'Nouvelle-Zélande' = 'New Zealand',
                                   'Italie' = 'Italy',
                                   'UE' = 'EU',
                                   'Allemagne' = 'Germany',
                                   'Autriche' = 'Austria'),
         `Product subgroup` = recode(`Product subgroup`,
                                     'Lait cru CH' = 'CH Milk ',
                                     'Lait cru, International' = 'International Milk'),  # Ajustez selon vos données
         `Sales region` = recode(`Sales region`,
                                 'Suisse' = 'Switzerland',
                                 'Nouvelle-Zélande' = 'New Zealand',
                                 'Italie' = 'Italy',
                                 'UE-28' = 'EU-28',
                                 'Allemagne' = 'Germany',
                                 'Autriche' = 'Austria'))  # Ajustez selon vos données

# Définir le chemin exact où enregistrer le fichier
file_path <- '../data/clean_data.csv'

# Enregistrer le DataFrame dans un fichier CSV à l'emplacement spécifié
write.csv(clean_data, file = file_path, row.names = FALSE)
```

```{r}
library(reactable)
library(readr)

# Lire le fichier CSV
clean_data <- read_csv("../data/clean_data.csv", show_col_types = FALSE)

# Afficher les données en utilisant reactable
reactable(clean_data)
```

#### Description

The data covers the period from January 2001 to January 2024. 
It provides information of the type of system of production : conventional, bio, or IP Swiss production of milk. 
The origin and the sales region of the milk include Switzerland and its regions, as well as other international countries. This will enable us to carry out comparative analyses of Swiss and international milk prices.
The 'Price' column represents the weighted average prices per quantity, mainly at the farm. 

```{r}
# Créez une table tibble avec des descriptions des variables
variable_table <- tibble(
  Variable = c("Date", "System of production", "Product origin", "Product subgroup", "Sales region", "Price"),
  Description = c(
    "The date when the data was recorded, in a year-month-day format.",
    "The system of production for the product.",
    "The origin of the product.",
    "The subgroup to which the product belongs.",
    "The region where the product is sold.",
    "The price in centimes of the product."
  )
)

# Affichez la table avec kableExtra
variable_table %>%
  kbl() %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "bordered", "hover", "condensed"))
```


The columns with missing values on our sub data set are: Sales region and System of production.
The 'System of production' has a higher percentage of missing values, around 37.6%.
However, this is a key variable in our analysis so we keep it and replace missing information 'NaN' with 'Unknown' for clarity.
As for Sales region, the percentage of missing values is relatively low thus we keep it.



### Swiss dairy products market

#### Wrangling & Cleaning

The main objective of this project is to focus on milk producers in Switzerland and more specifically on their remuneration.
To do this, we are going to create a sub data set 'swiss_production_data' that will only keep the Swiss regions in 'Product origin'.

```{r}
# Sélectionner les colonnes spécifiées
selected_columns <- c('Date', 'System of production', 'Product origin', 'Price')
subset_data <- clean_data %>%
  select(all_of(selected_columns))

# Définir les régions à conserver
regions_to_keep <- c('Region 1', 'Region 2', 'Region 3', 'Region 4', 'Region 5')
swiss_production_data <- subset_data %>%
  filter(`Product origin` %in% regions_to_keep)

# Remplacer les valeurs manquantes par 'Unknown'
swiss_production_data <- swiss_production_data %>%
  mutate(across(everything(), ~replace_na(., 'Unknown')))

# Définir le chemin exact où enregistrer le fichier
file_path <- '../data/swiss_production_data.csv'

# Enregistrer le DataFrame dans un fichier CSV à l'emplacement spécifié
write.csv(swiss_production_data, file = file_path, row.names = FALSE)
```

```{r}
# Lire le fichier CSV
swiss_production_data <- read_csv("../data/swiss_production_data.csv", show_col_types = FALSE)

# Afficher les données en utilisant reactable
reactable(swiss_production_data)
```


#### Description

Here is the geographical distribution of the 5 regions in Switzerland. 

```{r}
# Créez une table tibble avec des descriptions des variables
table <- tibble(
  Variable = c("Region 1", "Region 2", "Region 3", "Region 4", "Region 5"),
  Description = c(
    "Geneva, Vaud, Fribourg, Neuchâtel, Jura and the French-speaking parts of the canton of Bern (administrative district of Bernese Jura).",      "Bern, except the administrative district of Jura Bernois, Lucerne, Unterwalden : Obwalden. Nidwalden, Uri, Zug and part of the canton of      Schwyz (district of Schwyz, Gersau and Küssnacht).",
    "Basel-Landschaft and Basel-Stadt, Aargau and Solothurn",
    "Zurich, Schaffhausen, Thurgau. Appenzell (Inner and Outer Rhodes), St. Gallen, part of Canton Schwyz (districts of Einsiedeln, March and       Höfe), Glarus, Graubünden",
    "Valais and Ticino"
  )
)

# Affichez la table avec kableExtra
table %>%
  kbl() %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "bordered", "hover", "condensed"))
```



## Lait Equitable Sales

### Dataset Sales 2023

#### Wrangling and Cleaning

```{python}
file_path = '../data/all_products_sales_per_stores_2023.xlsx'
df = pd.read_excel(file_path, sheet_name='Sheet1')

df.columns = df.columns.astype(str)
# Renaming the monthly columns for easier readability
new_column_names = {
    '2023-01-01 00:00:00': 'Jan 2023',
    '2023-02-01 00:00:00': 'Feb 2023',
    '2023-03-01 00:00:00': 'Mar 2023',
    '2023-04-01 00:00:00': 'Apr 2023',
    '2023-05-01 00:00:00': 'May 2023',
    '2023-06-01 00:00:00': 'Jun 2023',
    '2023-07-01 00:00:00': 'Jul 2023',
    '2023-08-01 00:00:00': 'Aug 2023',
    '2023-09-01 00:00:00': 'Sep 2023',
    '2023-10-01 00:00:00': 'Oct 2023',
    '2023-11-01 00:00:00': 'Nov 2023',
    '2023-12-01 00:00:00': 'Dec 2023'
}
df.rename(columns=new_column_names, inplace=True)

# Standardize city names based on the mapping provided
correct_city_names = {
    'Bâle': 'Basel',
    'Genève': 'Geneva',
    'Bienne': 'Biel/Bienne',
    'Chavannes': 'Chavannes-de-Bogis',
    'Marin': 'Marin-Epagnier',
    'Vesenaz': 'Vésenaz',
    'Yverdon': 'Yverdon-les-Bains',
    'Saint-Gall Webersbleiche': 'St. Gall'
}
df['Row Labels'] = df['Row Labels'].apply(lambda x: correct_city_names.get(x, x))
```

The dataset from 2023 was meticulously cleaned and standardized to ensure accuracy in our analysis.
Initial steps included loading the data from an Excel file and renaming columns to reflect clearer, month-specific sales data for easier readability.
Additionally, we corrected city names to maintain consistency across datasets.
This included mapping various forms of city names to their standardized counterparts (e.g., 'Bâle' to 'Basel').

#### Description

The dataset is very light and contains monthly sales data for the year 2023.
It is essential however for the analysis of the sales of Lait Equitable in different Manor stores.

Here is a preview of the cleaned and structured data:

```{r warning=FALSE, message=FALSE}
#load python df
df_sales_2023 <- py$df

# Load necessary libraries
library(tibble)
library(kableExtra)

# Create a tibble with variable descriptions for df_manor_sales
variable_table <- tibble(
  Variable = c("Row Labels", "Monthly Columns (2023-01-01 to 2023-12-01)", "Grand Total"),
  Description = c(
    "Identifies the Manor store location by name.",
    "Each column represents sales figures for a specific month of 2023",
    "Total sales across all months of 2023 for each location"
  )
)

# Display the table using kableExtra
variable_table %>%
  kbl() %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "bordered", "hover", "condensed"))

# Using the provided column names correctly in the dataframe df_sales_2023
df_sales_2023_show <- df_sales_2023 %>%
  # Ensure you convert the column names to standard ones if needed
  rename(Location = `Row Labels`) %>%
  # Correctly sum the monthly sales columns from Jan 2023 to Dec 2023
  mutate(Total_Sales = rowSums(select(., `Jan 2023`:`Dec 2023`), na.rm = TRUE)) %>%
  select(Location, `Jan 2023`:`Dec 2023`, Total_Sales) %>%
  mutate_if(is.numeric, round, 2)  # round all numeric columns to 2 decimal places

# Display the data using reactable for an interactive table
reactable(
  df_sales_2023_show,  
  highlight = TRUE,  # Highlight rows on hover
  defaultPageSize = 10,  # Display 10 rows per page
  paginationType = "numbers",  # Use numbers for page navigation
  searchable = TRUE,  # Make the table searchable
  sortable = TRUE,  # Allow sorting
  resizable = TRUE  # Allow column resizing
)
```

### Dataset Sales 2022

#### Wrangling and Cleaning

Following the methodology established with the 2023 dataset, the 2022 sales data was similarly processed.
The data from 2022, while structurally different, was also standardized to facilitate comparison and analysis.
This included renaming columns to ensure uniformity in location names across both datasets.

```{python}
# Load the data for 2022
file_path_2022 = '../data/sales_2022.xlsx'
df_2022 = pd.read_excel(file_path_2022)

# Standardize city names based on the provided mapping
city_name_mapping = {
    'Bâle': 'Basel',
    'Genève': 'Geneva',
    'Bienne': 'Biel/Bienne',
    'Chavannes': 'Chavannes-de-Bogis',
    'Marin': 'Marin-Epagnier',
    'Vesenaz': 'Vésenaz',
    'Yverdon': 'Yverdon-les-Bains',
    'Saint-Gall Webersbleiche': 'St. Gall'
}

# Rename columns to standardize city names
df_2022.rename(columns=city_name_mapping, inplace=True)

# Pivoting the table to get total sales per location for 2022, summing across all products
sales_columns_2022 = [col for col in df_2022.columns if col not in ['Code article', 'Description article', 'Marque', 'Code Fournisseur', 'Description Fournisseur']]
df_2022_total_sales = df_2022[sales_columns_2022].sum().reset_index()
df_2022_total_sales.columns = ['Location', 'Total Sales 2022']
```

#### Description

The 2022 dataset, unlike the 2023 dataset, includes a variety of products, each recorded with sales figures across different locations.
This dataset is notably less complex, focusing on total sales rather than monthly breakdowns, yet provides critical insights into the sales performance of different products.

```{r}
# Load the 2022 sales data
df_sales_2022 <- py$df_2022
# Load necessary libraries
library(tibble)
library(kableExtra)

# Create a tibble with variable descriptions for df_sales
variable_table <- tibble(
  Variable = c("Code article", "Description article", "Marque", "Code Fournisseur", "Description Fournisseur",
               "Location Columns (e.g., Ascona-Delta, Baden, Bâle, etc.)"),
  Description = c(
    "Unique identifier for each product.",
    "Descriptive name of the product.",
    "Brand of the product.",
    "Supplier code.",
    "Supplier name.",
    "Each of these columns represents sales figures for that specific location."
  )
)

# Display the table using kableExtra
variable_table %>%
  kbl() %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "bordered", "hover", "condensed"))
```

Here is a closer look at the structured 2022 sales data:

```{r}
library(dplyr)
library(reactable)

# Assuming the dataframe is correctly named df_sales_2022 and is already loaded
# Ensure the dataframe is available in your R environment
print(head(df_sales_2022))

# Prepare the data by calculating the total sales per product across all locations
df_sales_2022_show <- df_sales_2022 %>%
  mutate(Total_Sales = rowSums(select(., `Ascona-Delta`:`Yverdon-les-Bains`), na.rm = TRUE)) %>%
  select(`Code article`, `Description article`, `Marque`, `Code Fournisseur`, `Description Fournisseur`, `Ascona-Delta`:`Yverdon-les-Bains`, Total_Sales) %>%
  mutate_if(is.numeric, round, 2)  # Round all numeric columns to 2 decimal places

# Display the data using reactable for an interactive and visually appealing table
reactable(
  df_sales_2022_show,
  highlight = TRUE,
  defaultPageSize = 5,
  paginationType = "numbers",
  searchable = TRUE,
  sortable = TRUE,
  resizable = TRUE
)

```

#### Merging 2022 and 2023 dataset

```{python}
# Extracting the total sales for 2023 from the first dataset
df_2023_total_sales = df[['Row Labels', 'Grand Total']].rename(columns={'Row Labels': 'Location', 'Grand Total': 'Total Sales 2023'})

# Merging the 2022 and 2023 datasets on Location
merged_sales_data = pd.merge(df_2022_total_sales, df_2023_total_sales, on='Location', how='outer')

# Filling any NaN values that might have occurred due to locations present in one dataset and not the other
merged_sales_data.fillna(0, inplace=True)
```

```{r}
# Load the merged sales data
df_merged_sales <- py$merged_sales_data
#show it using reactable
reactable(
  df_merged_sales,  
  highlight = TRUE,  # Highlight rows on hover
  defaultPageSize = 10,  # Display 10 rows per page
  paginationType = "numbers",  # Use numbers for page navigation
  searchable = TRUE,  # Make the table searchable
  sortable = TRUE,  # Allow sorting
  resizable = TRUE  # Allow column resizing
)
```

The 2022 sales data has been aggregated and standardized for each location.
The merged dataset now shows the total sales per location for both 2022 and 2023.
This dataset offers a comprehensive view of Lait Equitable's sales dynamics over two consecutive years, highlighting trends and changes in consumer behavior across different locations.

### Political Parties Dataset

#### Wrangling and Cleaning

The analysis starts by importing two datasets: sales data (annual sales of fair trade milk) and political party data (support percentages for major parties by location).
The political data is cleaned to match commune names in the sales data and transformed into party presence percentages.

Next, the cleaned political data is merged with the sales data based on commune names.
This merged dataset enables a combined analysis of political party presence and sales performance.

```{r}
# Read sales data from Excel
sales_data <- read_excel("../data/Ventes annuelles.xlsx")

# Read political party data from Excel
party_data <- read_excel("../data/partisPolitiqueManor.xlsx")

# Clean up party_data to match sales_data locations
party_data_cleaned <- party_data %>%
  mutate(Location = gsub(" ", "", Location)) %>%
  filter(Location %in% sales_data$Location)

# Update party names to match the new column names
party_data_cleaned <- party_data_cleaned %>%
  mutate(PLR_Presence = PLR / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100,
         PS_Presence = PS / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100,
         UDC_Presence = UDC / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100,
         Centre_Presence = Centre / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100,
         Verts_Presence = Verts / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100,
         Vertliberaux_Presence = Vertliberaux / (PLR + PS + UDC + Centre + Verts + Vertliberaux) * 100) %>%
  filter(PLR_Presence > 0.2 | PS_Presence > 0.2 | UDC_Presence > 0.2 | Centre_Presence > 0.2 | Verts_Presence > 0.2 | Vertliberaux_Presence > 0.2)

# Merge sales_data with updated party presence data
merged_data <- merge(sales_data, party_data_cleaned, by = "Location")
```

The analysis starts by importing one other dataset: revenue per capita per commune data.
The revenue data is cleaned to match commune names in the sales data.

Next, the cleaned revenue data is merged with the sales data based on commune names.
This merged dataset enables a combined analysis of revenue per capita per commune and sales performance.

```{r}
# Load the datasets
revenu_df <- read_excel("../data/revenuParContribuable_CommuneManor.xlsx")

# Merge the datasets on the "Location" column
merged_df <- inner_join(revenu_df, sales_data, by = "Location")

# Clean the data and convert to numeric format
merged_df$`Revenu/contribuable` <- as.numeric(gsub(" ", "", merged_df$`Revenu/contribuable`))
merged_df$`2022` <- as.numeric(gsub(" ", "", merged_df$`2022`))
merged_df$`2023` <- as.numeric(gsub(" ", "", merged_df$`2023`))
```

#### Description

Write kableextra to describe the dataset here

```{r}

```

```{r}
# Display the merged data using reactable
reactable(
  merged_data,  
  highlight = TRUE,  # Highlight rows on hover
  defaultPageSize = 10,  # Display 10 rows per page
  paginationType = "numbers",  # Use numbers for page navigation
  searchable = TRUE,  # Make the table searchable
  sortable = TRUE,  # Allow sorting
  resizable = TRUE  # Allow column resizing
)

```

UTILISER CODE POUR DISPLAY DATA (JAYESH)
